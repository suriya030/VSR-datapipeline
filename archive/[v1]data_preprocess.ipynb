{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007388ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\qube-cinemas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting scenes in 96.mkv...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Detected: 2122 | Progress: 100%|█████████▉| 227672/227673 [22:09<00:00, 171.30frames/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2123 scenes.\n",
      "Splitting video into scenes in folder: movie_scenes\\96-AdaptiveDetector\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227672/227672 [42:46<00:00, 88.72frame/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video successfully split into scenes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from scenedetect import open_video, SceneManager\n",
    "from scenedetect.detectors import ContentDetector, AdaptiveDetector\n",
    "# The new, correct way for PySceneDetect v0.6+\n",
    "from scenedetect.video_splitter import split_video_ffmpeg\n",
    "\n",
    "\n",
    "def find_and_split_scenes(video_path, output_dir):\n",
    "    \"\"\"\n",
    "    Finds content-based scenes in a video and splits the video into\n",
    "    separate files for each scene.\n",
    "\n",
    "    Args:\n",
    "        video_path (str): Path to the input video.\n",
    "        output_dir (str): Folder to save the scene clips.\n",
    "    \"\"\"\n",
    "    # 1. Open the video and create a SceneManager\n",
    "    video = open_video(video_path)\n",
    "    scene_manager = SceneManager()\n",
    "\n",
    "    # 2. Add a detector. AdaptiveDetector is great for high-motion content.\n",
    "    # The adaptive_threshold is the sensitivity of the detector relative to the\n",
    "    # video's motion. A good starting point is 3.0. Lower values detect\n",
    "    # more scenes, higher values detect fewer.\n",
    "    scene_manager.add_detector(AdaptiveDetector(adaptive_threshold=3.0))\n",
    "\n",
    "    # 3. Run the scene detection\n",
    "    print(f\"Detecting scenes in {os.path.basename(video_path)}...\")\n",
    "    scene_manager.detect_scenes(video=video, show_progress=True)\n",
    "\n",
    "    # 4. Get the list of scenes found\n",
    "    # Each scene is a tuple of (start_time, end_time)\n",
    "    scene_list = scene_manager.get_scene_list()\n",
    "\n",
    "    print(f\"Found {len(scene_list)} scenes.\")\n",
    "\n",
    "    if not scene_list:\n",
    "        print(\"No scenes detected.\")\n",
    "        return\n",
    "\n",
    "    # 5. (Optional but Recommended) Split the video into clips\n",
    "    # This will create a separate video file for each detected scene.\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Splitting video into scenes in folder: {output_dir}\")\n",
    "    \n",
    "    # split_video_ffmpeg uses the command-line tool ffmpeg.\n",
    "    # Ensure ffmpeg is installed and accessible in your system's PATH.\n",
    "    try:\n",
    "        split_video_ffmpeg(video_path, scene_list, output_dir=output_dir,\n",
    "                           show_progress=True)\n",
    "        print(\"Video successfully split into scenes.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error splitting video: {e}\")\n",
    "        print(\"Please ensure ffmpeg is installed and in your system's PATH.\")\n",
    "\n",
    "\n",
    "\n",
    "movie_path = r\"movie\\EmpuraanLucif2_TSR_TA-XX_4K-51-DOM_20250125_video-002.mxf\"\n",
    "output_folder = r\"movie_scenes\\EmpuraanLucif2_TSR_TA-XX_4K-51-DOM_20250125_video-002\"\n",
    "\n",
    "find_and_split_scenes(movie_path, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4c446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import pyiqa\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ==============================================================================\n",
    "# Core Function to Find and Extract High-Quality Frame Sequence\n",
    "# ==============================================================================\n",
    "\n",
    "def find_first_sequence_musiq_niqe(\n",
    "    video_path,\n",
    "    output_folder,\n",
    "    musiq_metric,\n",
    "    niqe_metric,\n",
    "    device,\n",
    "    sequence_length=15,\n",
    "    musiq_threshold=35.0,\n",
    "    niqe_threshold=6.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Finds the first sequence of high-quality frames in a video using a\n",
    "    combination of MUSIQ and NIQE metrics, then saves the sequence and stops.\n",
    "    \"\"\"\n",
    "    # --- 1. Initialization ---\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video {video_path}\")\n",
    "        return\n",
    "\n",
    "    frame_buffer = deque(maxlen=sequence_length)\n",
    "    frame_count = 0\n",
    "    base_video_name = os.path.basename(video_path).split('.')[0]\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    print(f\"\\n--- Processing {base_video_name} ({total_frames} frames) | MUSIQ > {musiq_threshold}, NIQE < {niqe_threshold} ---\")\n",
    "\n",
    "    # --- 2. Frame-by-Frame Processing Loop ---\n",
    "    with tqdm(total=total_frames, desc=f\"Scanning {base_video_name}\", unit=\"frame\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            frame_count += 1\n",
    "            pbar.update(1)\n",
    "\n",
    "            # --- 2a. Pre-processing and Quality Checks ---\n",
    "            # Skip blank/black frames to avoid corrupting the sequence\n",
    "            if np.std(frame) < 10.0:\n",
    "                frame_buffer.clear()\n",
    "                continue\n",
    "\n",
    "            # Convert frame to a tensor for the IQA models\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame_tensor = torch.tensor(frame_rgb).permute(2, 0, 1).unsqueeze(0) / 255.0\n",
    "            frame_tensor = frame_tensor.to(device)\n",
    "\n",
    "            # Calculate quality scores\n",
    "            with torch.no_grad():\n",
    "                musiq_score = musiq_metric(frame_tensor).item()\n",
    "                niqe_score = niqe_metric(frame_tensor).item()\n",
    "\n",
    "            # --- 2b. Buffer Management ---\n",
    "            # A frame is \"good\" if it passes both quality thresholds\n",
    "            is_good_quality = (musiq_score >= musiq_threshold) and (niqe_score <= niqe_threshold)\n",
    "\n",
    "            if is_good_quality:\n",
    "                # Add good frames to the buffer\n",
    "                frame_buffer.append({'frame_num': frame_count, 'frame': frame})\n",
    "            else:\n",
    "                # If a frame is of poor quality, the sequence is broken. Reset the buffer.\n",
    "                frame_buffer.clear()\n",
    "\n",
    "            # --- 2c. Save Sequence and Exit Condition ---\n",
    "            # If the buffer is full, we have found a complete, high-quality sequence\n",
    "            if len(frame_buffer) == sequence_length:\n",
    "                print(f\"\\nSUCCESS: Found a valid sequence of {sequence_length} frames in {base_video_name}. Saving...\")\n",
    "                sequence_dir = os.path.join(output_folder, f\"{base_video_name}_sequence_musiq_niqe\")\n",
    "                os.makedirs(sequence_dir, exist_ok=True)\n",
    "\n",
    "                for frame_data in frame_buffer:\n",
    "                    file_path = os.path.join(sequence_dir, f\"frame_{frame_data['frame_num']:06d}.png\")\n",
    "                    cv2.imwrite(file_path, frame_data['frame'])\n",
    "\n",
    "                break  # Sequence found, exit the loop for this video\n",
    "\n",
    "    # --- 3. Final Status Report ---\n",
    "    if len(frame_buffer) < sequence_length:\n",
    "        print(f\"--- FAILED to find a full sequence in {base_video_name}. Max consecutive frames found: {len(frame_buffer)} ---\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- 1. Configuration ---\n",
    "    scenes_input_folder = r\"movie_scenes\\Beast-AdaptiveDetector\"\n",
    "    final_dataset_folder = r\"movie_frames\\Beast-AdaptiveDetector\"\n",
    "\n",
    "    if not os.path.isdir(scenes_input_folder):\n",
    "        print(f\"Error: Input directory not found at {scenes_input_folder}\")\n",
    "    else:\n",
    "        # --- 2. Setup IQA Models ---\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Initializing IQA models on device: {device}\")\n",
    "\n",
    "        try:\n",
    "            musiq_metric = pyiqa.create_metric('musiq', device=device)\n",
    "            niqe_metric = pyiqa.create_metric('niqe', device=device)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to create IQA models: {e}\")\n",
    "            exit()\n",
    "\n",
    "        # --- 3. Process Videos ---\n",
    "        print(\"Starting sequence extraction...\")\n",
    "        video_files = sorted([f for f in os.listdir(scenes_input_folder) if f.endswith((\".mp4\", \".avi\", \".mov\", \".mkv\"))])\n",
    "\n",
    "        for video_file in video_files:\n",
    "            video_path = os.path.join(scenes_input_folder, video_file)\n",
    "            find_first_sequence_musiq_niqe(\n",
    "                video_path,\n",
    "                final_dataset_folder,\n",
    "                musiq_metric=musiq_metric,\n",
    "                niqe_metric=niqe_metric,\n",
    "                device=device\n",
    "            )\n",
    "\n",
    "        print(\"\\nAll scenes processed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qube-cinemas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
